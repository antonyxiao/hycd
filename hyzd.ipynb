{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e6c5ce1d-0e37-4900-a585-f3f213ded066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "\n",
    "data = pickle.load(open('wiki.pkl', 'rb'))\n",
    "#word_table = pickle.load(open('word_table.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d1dfdd64-5379-4a52-92b2-492401fbf38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "\n",
    "def get_conn():\n",
    "    try:\n",
    "        # Connect to the MySQL database\n",
    "        connection = mysql.connector.connect(\n",
    "            host='localhost',       # Replace with your host name\n",
    "            port=3306,              # Replace with your port number if different\n",
    "            user='root',   # Replace with your username\n",
    "            password='debang', # Replace with your password\n",
    "            database='hyzd' # Replace with your database name\n",
    "        )\n",
    "        \n",
    "        if connection.is_connected():\n",
    "            db_info = connection.get_server_info()\n",
    "            #print(\"Connected to MySQL Server version \", db_info)\n",
    "            return connection\n",
    "        \n",
    "    except Error as e:\n",
    "        print(\"Error while connecting to MySQL\", e)\n",
    "\n",
    "def close_conn(connection):\n",
    "    if connection.is_connected():\n",
    "        connection.cursor().close()\n",
    "        connection.close()\n",
    "        #print(\"MySQL connection is closed\")\n",
    "\n",
    "def load_word_table_into_db():\n",
    "    conn = get_conn()\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    data = []\n",
    "    \n",
    "    for key, value in word_table.items():\n",
    "        for v in value:\n",
    "            data.append((key, v))\n",
    "\n",
    "    sql = \"INSERT INTO char_table (ch, id) VALUES (%s, %s)\"\n",
    "    \n",
    "    cursor.executemany(sql, data)\n",
    "    conn.commit()\n",
    "\n",
    "    close_conn(conn)\n",
    "        \n",
    "    #records = cursor.fetchall()\n",
    "\n",
    "def get_id_from_char(char):\n",
    "\n",
    "    conn = get_conn()\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute('SELECT id FROM char_table WHERE ch = %s', (char,))\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    id_values = [row[0] for row in rows]\n",
    "    \n",
    "    close_conn(conn)\n",
    "\n",
    "    return id_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2d77c8ff-5c54-4148-b6b4-679f1172a06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sounds(input_char):\n",
    "    for i in get_id_from_char(input_char):\n",
    "        print('INDEX: ' + str(i))\n",
    "        if 'sounds' in data[i]:\n",
    "            sounds = data[i]['sounds']\n",
    "            for s in sounds:\n",
    "                if 'tags' in s:\n",
    "                    if ('Mandarin' in s['tags'] and 'Pinyin' in s['tags'] and ( len(s['tags']) == 2 or 'standard' in s['tags'])) and not any(x in s['zh-pron'] for x in ['⁰', '¹', '²', '³', '⁴', '⁵']):\n",
    "                        print('PY: ' + s['zh-pron'])\n",
    "                    if 'Cantonese' in s['tags'] and 'Jyutping' in s['tags']:\n",
    "                        print('JP: ' + s['zh-pron'])\n",
    "                    if 'Middle-Chinese' in s['tags']:\n",
    "                        print('MC: ' + s['zh-pron'])\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "68798ca7-1001-4df8-a22b-0c4951e7c154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from hanziconv import HanziConv\n",
    "\n",
    "def get_emin(sounds, ipa=True):\n",
    "    '''\n",
    "    Returns a list of unique min dong (eastern min) pronunciations\n",
    "    '''\n",
    "    # Extract zh-pron and ipa where tags contain Min-Dong\n",
    "    zh_pron_values = [(entry.get('zh-pron', None), entry.get('ipa', None)) for entry in sounds if 'Min-Dong' in entry.get('tags', [])]\n",
    "    \n",
    "    # Filter out None values\n",
    "    zh_pron_values = [(zh_pron, ipa) for zh_pron, ipa in zh_pron_values if zh_pron is not None or ipa is not None]\n",
    "\n",
    "    pronunciations = []\n",
    "    \n",
    "    for zh_pron, ipa_pron in zh_pron_values:\n",
    "        if zh_pron is not None:\n",
    "            pronunciations.append(zh_pron)\n",
    "        if ipa == True and ipa_pron is not None:\n",
    "            pronunciations.append(ipa_pron)\n",
    "    \n",
    "    return list(set(pronunciations))\n",
    "\n",
    "def get_pinyin(sounds):\n",
    "    for s in sounds:\n",
    "        if 'tags' in s:\n",
    "            if ('Mandarin' in s['tags'] and 'Pinyin' in s['tags'] and ( len(s['tags']) == 2 or 'standard' in s['tags'])) and not any(x in s['zh-pron'] for x in ['⁰', '¹', '²', '³', '⁴', '⁵']):\n",
    "                return [s['zh-pron'].lower()]\n",
    "\n",
    "def get_jp(sounds):\n",
    "    for s in sounds:\n",
    "        if 'tags' in s:\n",
    "            if 'Cantonese' in s['tags'] and 'Jyutping' in s['tags']:\n",
    "                return [s['zh-pron'].lower().replace('¹', '1').replace('²', '2').replace('³', '3')\n",
    "                       .replace('⁴', '4').replace('⁵', '5').replace('⁶', '6')]\n",
    "\n",
    "def get_mc(sounds):\n",
    "    for s in sounds:\n",
    "        if 'tags' in s:\n",
    "            if 'Middle-Chinese' in s['tags']:\n",
    "                return [s['zh-pron'].lower()]\n",
    "\n",
    "import chinese_converter\n",
    "\n",
    "def get_prons(ch):\n",
    "    ch = HanziConv.toTraditional(ch)\n",
    "    char_prons = dict()\n",
    "    i = 0 \n",
    "    for index in get_id_from_char(ch):\n",
    "\n",
    "        if 'sounds' in data[index]:\n",
    "        \n",
    "            sounds = data[index]['sounds']\n",
    "            \n",
    "            emin = get_emin(sounds, ipa=False)\n",
    "            py = get_pinyin(sounds)\n",
    "            jp = get_jp(sounds)\n",
    "            mc = get_mc(sounds)\n",
    "            \n",
    "            # None if exact pronunciation already exists\n",
    "            char_prons[i] = {\n",
    "                'md': emin if emin not in [entry.get('md') for entry in char_prons.values()] else None,\n",
    "                'py': py if py not in [entry.get('py') for entry in char_prons.values()] else None,\n",
    "                'jp': jp if jp not in [entry.get('jp') for entry in char_prons.values()] else None,\n",
    "                'mc': mc if mc not in [entry.get('mc') for entry in char_prons.values()] else None\n",
    "            }\n",
    "            \n",
    "            i += 1\n",
    "    \n",
    "    filtered_char_prons = dict()\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for key, entry_list in char_prons.items():\n",
    "        non_none_values = [(k, v) for k, v in entry_list.items() if v]\n",
    "        if non_none_values:\n",
    "            temp_dict = {'md': None, 'py': None, 'jp': None, 'mc': None}\n",
    "            for k, v in non_none_values:\n",
    "                 temp_dict[k] = v\n",
    "            filtered_char_prons[i] = temp_dict\n",
    "            i += 1\n",
    "        \n",
    "    return filtered_char_prons\n",
    "\n",
    "def romanize(str):\n",
    "    lo_romanization = []\n",
    "    for char in str:\n",
    "        lo_romanization.append(get_prons(char))\n",
    "\n",
    "    return lo_romanization\n",
    "\n",
    "def get_pron_with_py(ch, py):\n",
    "    prons = get_prons(ch)\n",
    "    for key, item in prons.items():\n",
    "        if item['py']:\n",
    "            if py in item['py']:\n",
    "                return item\n",
    "\n",
    "    return {'jp': None, 'mc': None, 'md': None, 'py': None}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "554bcb55-d15d-4743-a156-cd596f04573d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'md': None, 'py': ['hú'], 'jp': ['wu4'], 'mc': None}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get_prons('和')\n",
    "get_pron_with_py('和', 'hú')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "230a82c6-a0b4-4a54-a44f-e8fc4d6f1da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing dictionary . . .\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#A parser for the CC-Cedict. Convert the Chinese-English dictionary into a list of python dictionaries with \"traditional\",\"simplified\", \"pinyin\", and \"english\" keys.\n",
    "\n",
    "#Make sure that the cedict_ts.u8 file is in the same folder as this file, and that the name matches the file name on line 13.\n",
    "\n",
    "#Before starting, open the CEDICT text file and delete the copyright information at the top. Otherwise the program will try to parse it and you will get an error message.\n",
    "\n",
    "#Characters that are commonly used as surnames have two entries in CC-CEDICT. This program will remove the surname entry if there is another entry for the character. If you want to include the surnames, simply delete lines 59 and 60.\n",
    "\n",
    "#This code was written by Franki Allegra in February 2020.\n",
    "\n",
    "#open CEDICT file\n",
    "\n",
    "with open('cedict_ts.u8') as file:\n",
    "    text = file.read()\n",
    "    lines = text.split('\\n')\n",
    "    dict_lines = list(lines)\n",
    "\n",
    "#define functions\n",
    "\n",
    "    def parse_line(line):\n",
    "        parsed = {}\n",
    "        if line == '':\n",
    "            dict_lines.remove(line)\n",
    "            return 0\n",
    "        line = line.rstrip('/')\n",
    "        line = line.split('/')\n",
    "        if len(line) <= 1:\n",
    "            return 0\n",
    "        english = line[1]\n",
    "        char_and_pinyin = line[0].split('[')\n",
    "        characters = char_and_pinyin[0]\n",
    "        characters = characters.split()\n",
    "        traditional = characters[0]\n",
    "        simplified = characters[1]\n",
    "        pinyin = char_and_pinyin[1]\n",
    "        pinyin = pinyin.rstrip()\n",
    "        pinyin = pinyin.rstrip(\"]\")\n",
    "        parsed['traditional'] = traditional\n",
    "        parsed['simplified'] = simplified\n",
    "        parsed['pinyin'] = pinyin\n",
    "        parsed['english'] = english\n",
    "        list_of_dicts.append(parsed)\n",
    "\n",
    "    def remove_surnames():\n",
    "        for x in range(len(list_of_dicts)-1, -1, -1):\n",
    "            if \"surname \" in list_of_dicts[x]['english']:\n",
    "                if list_of_dicts[x]['traditional'] == list_of_dicts[x+1]['traditional']:\n",
    "                    list_of_dicts.pop(x)\n",
    "            \n",
    "    def main():\n",
    "\n",
    "        #make each line into a dictionary\n",
    "        print(\"Parsing dictionary . . .\")\n",
    "        for line in dict_lines:\n",
    "                parse_line(line)\n",
    "        \n",
    "        #remove entries for surnames from the data (optional):\n",
    "\n",
    "        #print(\"Removing Surnames . . .\")\n",
    "        #remove_surnames()\n",
    "\n",
    "        return list_of_dicts\n",
    "\n",
    "\n",
    "        #If you want to save to a database as JSON objects, create a class Word in the Models file of your Django project:\n",
    "\n",
    "        # print(\"Saving to database (this may take a few minutes) . . .\")\n",
    "        # for one_dict in list_of_dicts:\n",
    "        #     new_word = Word(traditional = one_dict[\"traditional\"], simplified = one_dict[\"simplified\"], english = one_dict[\"english\"], pinyin = one_dict[\"pinyin\"], hsk = one_dict[\"hsk\"])\n",
    "        #     new_word.save()\n",
    "        print('Done!')\n",
    "\n",
    "list_of_dicts = []\n",
    "parsed_dict = main()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "45fa97f5-e364-4708-8614-53855a1291b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'traditional': '齯', 'simplified': '𫠜', 'pinyin': 'ni2', 'english': 'teeth grown in old age'}\n"
     ]
    }
   ],
   "source": [
    "for entry in parsed_dict:\n",
    "    if '𫠜' == entry['simplified']:\n",
    "        print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c1331f83-b87b-401c-a582-1edf64dcf616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'𨭎'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chinese_converter\n",
    "\n",
    "#HanziConv.toTraditional('启')\n",
    "HanziConv.toSimplified('𨭎')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9c5bd238-2e7c-439d-a5ef-cd0cc597aedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wu4\n"
     ]
    }
   ],
   "source": [
    "import pycantonese\n",
    "\n",
    "def get_jp_from_pycanto(char):\n",
    "    # Generate jyutping for the word, filtering out None values\n",
    "    jyutping_chunks = [\n",
    "        chunk[1] for chunk in pycantonese.characters_to_jyutping(HanziConv.toTraditional(char))\n",
    "        if chunk[1] is not None\n",
    "    ]\n",
    "    jyutping = ' '.join(jyutping_chunks)\n",
    "\n",
    "    return jyutping\n",
    "\n",
    "def get_jp_with_py_pron(cur_char, pron):\n",
    "\n",
    "    jyutping = ''\n",
    "    \n",
    "    if not pron or 'jp' not in pron:\n",
    "        jyutping = get_jp_from_pycanto(cur_char)\n",
    "    elif pron['jp']:\n",
    "        jyutping = pron['jp'][0]\n",
    "    else:\n",
    "        jyutping = get_jp_from_pycanto(cur_char)\n",
    "\n",
    "    return jyutping\n",
    "\n",
    "pron = get_pron_with_py(HanziConv.toTraditional('和'), 'hú')    \n",
    "print(get_jp_with_py_pron('和', pron)) # should be wo6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1b5c32b8-2cca-4cc9-89b4-694c484a73e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "𫘤: ái\n",
      "𮩝: ài\n",
      "𩽾: ān\n",
      "鲃: bā\n",
      "𫜨: bà\n",
      "𫖔: bài\n",
      "𨭉: bān\n",
      "𠳐: bāng\n",
      "𬇙: bèi\n",
      "𮤲: bì\n",
      "𨚕: biàn\n",
      "𬭛: bō\n",
      "𬷕: bǔ\n",
      "𥮾: cǎn\n",
      "镵: chán\n",
      "𬊤: chǎn\n",
      "𬬮: chǎng\n",
      "𮧴: chàng\n",
      "𬘭: chēn\n",
      "铖: chéng\n",
      "𫄨: chī\n",
      "𫛶: chì\n",
      "䝙: chū\n",
      "𬸅: chú\n",
      "𬺓: chǔ\n",
      "𬭚: chún\n",
      "𫚖: cǐ\n",
      "酂: cuán\n",
      "酂: cuó又cuán\n",
      "𨱏: dā\n",
      "鿎: dá\n",
      "𫟼: dá\n",
      "𫄤: da\n",
      "𬘘: dǎn\n",
      "𫢸: dàn\n",
      "𣗋: dǎng\n",
      "𬍡: dàng\n",
      "𣱼: dāo\n",
      "䃅: dī\n",
      "𬱖: dí\n",
      "𤧛: dì\n",
      "䗖: dì\n",
      "𦰏: diào\n",
      "𫶇: dié\n",
      "𬟽: dōng\n",
      "𮙋: dú\n",
      "𬭊: dù\n",
      "𬭚: duì\n",
      "𫫇: è\n",
      "𫔍: fán\n",
      "𬸪: fán\n",
      "𬴂: fēi\n",
      "𣸣: fén\n",
      "𫓧: fū\n",
      "𫖯: fǔ\n",
      "𬮿: gài\n",
      "鿍: gàng\n",
      "鿔: gē\n",
      "𬮤: gé\n",
      "𮝴: gū\n",
      "䯄: guā\n",
      "𮉨: guā\n",
      "鳤: guǎn\n",
      "𨐈: guāng\n",
      "鬶: guī\n",
      "𭚦: guō\n",
      "啯: guō\n",
      "𬇹: guó\n",
      "𬌗: hé\n",
      "𮩝: hé\n",
      "𬭶: hēi\n",
      "𬣳: hén\n",
      "𫟹: hóng\n",
      "𭱊: hòng\n",
      "𬭤: hóu\n",
      "𬘫: huán\n",
      "𮝹: huán\n",
      "𤩽: huán\n",
      "𮝹: huàn\n",
      "𨱑: huáng\n",
      "㧑: huī\n",
      "𬭬: huì\n",
      "𬤝: huì\n",
      "𬴃: huō\n",
      "锪: huō\n",
      "𬯀: jī\n",
      "𫓹: jī\n",
      "𫌀: jī\n",
      "𬶨: jì\n",
      "𪟝: jì\n",
      "𬶭: jì\n",
      "𬂩: jiā\n",
      "篯: jiān\n",
      "𬣡: jiàn\n",
      "𬬱: jīn\n",
      "𬳶: jiōng\n",
      "䌹: jiǒng\n",
      "𬶋: jū\n",
      "钜: jù\n",
      "𪨗: juē\n",
      "𫘝: jué\n",
      "𫛞: jué\n",
      "𩾌: kāng\n",
      "𫸩: kōu\n",
      "𫛭: kuáng\n",
      "𫠆: kuǐ\n",
      "𬶟: là\n",
      "𬒗: lán\n",
      "𨱍: láng\n",
      "𫭼: láo\n",
      "𫄥: lí\n",
      "𫵷: lì\n",
      "𫟷: lì\n",
      "𬍛: lì\n",
      "梿: lián\n",
      "𬶠: liàn\n",
      "𫟅: liáng\n",
      "𬜯: liǎng\n",
      "𮉧: liǎng\n",
      "𪤗: liào\n",
      "𫚭: liè\n",
      "𬘭: lín\n",
      "𬴊: lín\n",
      "𬭸: lín\n",
      "𬕂: lǒng\n",
      "𪣻: lóu\n",
      "𦝼: lóu又lǘ\n",
      "硵: lǔ\n",
      "𫘧: lù\n",
      "𦝼: lǘ\n",
      "𬬭: lún\n",
      "𫭢: lún\n",
      "𫌨: luó\n",
      "㑩: luo\n",
      "祃: mà\n",
      "鿏: mài\n",
      "𬜬: màn\n",
      "𫞩: mén\n",
      "𫑡: méng\n",
      "𩾃: miǎn\n",
      "𬙊: mò\n",
      "𬭁: mǔ\n",
      "𫐐: ní\n",
      "𫠜: ní\n",
      "鿭: nǐ\n",
      "𨺙: nì\n",
      "𫔶: niè\n",
      "𬪩: nóng\n",
      "𫭟: ōu\n",
      "𬉼: ǒu\n",
      "𬳵: pī\n",
      "𬬫: pī\n",
      "𡎚: piǎn\n",
      "𬭯: piě\n",
      "𬞟: pín\n",
      "𨙸: qí\n",
      "𬨂: qí\n",
      ": qí\n",
      "伣: qiàn\n",
      "𬘬: qiàn\n",
      "𬧀: qiāng\n",
      "𬧀: qiàng\n",
      "𨱇: qiú\n",
      "𫭟: qū\n",
      "𪨰: qū\n",
      "𬒈: qué\n",
      "𫐓: róu\n",
      "𮉫: ruí\n",
      "𢫬: sà\n",
      "𫮃: shàn\n",
      "𪨶: shē\n",
      "𬳽: shēn\n",
      "𬬹: shén\n",
      "𫚕: shī\n",
      "𬤊: shì\n",
      "𬬸: shù\n",
      "𬢊: sì\n",
      "𫗧: sù\n",
      "𫟦: suì\n",
      "𬭼: suì\n",
      "鿎: tǎ\n",
      "𠉂: tà\n",
      "𬍡: tāng（又）\n",
      "𫘦: táo\n",
      "𫘨: tí\n",
      "𣨼: tì\n",
      "𫍣: tóng\n",
      "𬳿: tú\n",
      "𬯎: tuí\n",
      "𪨇: tuí\n",
      "𬶍: tuó\n",
      "𬇕: wàn\n",
      "𣲗: wéi\n",
      "𬶏: wéi\n",
      "𬀩: wěi\n",
      "𮧵: wěi\n",
      "𫇭: wěi\n",
      "𬱟: wěi\n",
      "鳚: wèi\n",
      "𬭬: wèi又huì\n",
      "𫘜: wén\n",
      "𬭩: wēng\n",
      "𣲘: wǔ\n",
      "㶉: xī\n",
      "锡: xī\n",
      "𫘬: xí\n",
      "𬭳: xǐ\n",
      "𬶮: xǐ\n",
      "𫰰: xiān\n",
      "𫍯: xián\n",
      "𤞤: xiǎn\n",
      "𬀪: xiàn\n",
      "𬭣: xiàn\n",
      "𬙋: xiāng\n",
      "蚃: xiǎng\n",
      "𫍲: xiǎo\n",
      "敩: xiào\n",
      "𫧯: xiè\n",
      "𬹼: xiè\n",
      "𤫉: xiè\n",
      "𫷷: xīn\n",
      "𫰛: xíng\n",
      "𬣙: xū\n",
      "媭: xū\n",
      "𦈡: xū\n",
      "𫓶: xuān\n",
      "𫍽: xuān\n",
      "𫠊: xuán\n",
      "碹: xuàn\n",
      "𫄸: xūn\n",
      "𬩽: xún\n",
      "㖊: xún\n",
      "𬍤: xún\n",
      "𬊈: xún\n",
      "𬘓: xún\n",
      "𫄧: yán\n",
      "𬸘: yǎn\n",
      "𬙂: yǎn\n",
      "𪩘: yǎn\n",
      "𫛩: yàn\n",
      "𬺈: yǐ\n",
      "𫖮: yǐ\n",
      "𬬩: yì\n",
      "𫄷: yì\n",
      "𬟁: yì\n",
      "𬘡: yīn\n",
      "𬤇: yīn\n",
      "𬮱: yīn\n",
      "訚: yín\n",
      "𦈠: yǐn\n",
      "𮐨: yīng\n",
      "𫘪: yuán\n",
      "𫐄: yuè\n",
      "𬸚: yuè\n",
      "𫖳: yūn\n",
      "筼: yún\n",
      "酂: zàn\n",
      "𥖨: zào\n",
      "𫗴: zhān\n",
      "𥇢: zhǎn\n",
      "𬬿: zhāo\n",
      "𬶐: zhào\n",
      "𦭜: zhī\n",
      "𬃊: zhì\n",
      "㤘: zhòu\n",
      "𬣞: zhǔ\n",
      "𬘯: zhǔn\n",
      "𬸦: zhuó\n",
      "咨: zī\n",
      "疭: zòng\n",
      "𮉪: zōu\n",
      "𨱔: zūn\n"
     ]
    }
   ],
   "source": [
    "import genanki\n",
    "import json\n",
    "import csv\n",
    "\n",
    "jp_and_mc_and_english = {}\n",
    "\n",
    "with open('xhzd_corrected.csv', newline='', encoding='utf-8') as csvfile:\n",
    "\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "\n",
    "    for row in spamreader:\n",
    "\n",
    "        jyutping = ''\n",
    "        mc = ''\n",
    "        cur_char = ''\n",
    "        english = ''\n",
    "        \n",
    "        if row[0][0] == ' ':\n",
    "            cur_char = row[0][1]\n",
    "        else:\n",
    "            cur_char = row[0][0]\n",
    "        \n",
    "        pron = get_pron_with_py(HanziConv.toTraditional(cur_char), row[3])\n",
    "        \n",
    "        jyutping = get_jp_with_py_pron(cur_char, pron)\n",
    "    \n",
    "        if pron['mc']:\n",
    "            mc = pron['mc'][0]\n",
    "\n",
    "        for entry in parsed_dict:\n",
    "            if cur_char == entry['simplified']:\n",
    "                english = entry['english']\n",
    "\n",
    "        if cur_char not in jp_and_mc_and_english:\n",
    "            jp_and_mc_and_english[cur_char] = {'jp': jyutping,'mc': mc, 'en': english}\n",
    "        else:\n",
    "            j = 2\n",
    "            while cur_char + str(j) in jp_and_mc_and_english:\n",
    "                j += 1\n",
    "            \n",
    "            jp_and_mc_and_english[cur_char + str(j)] = {'jp': jyutping,'mc': mc, 'en': english}\n",
    "\n",
    "        if not jyutping:\n",
    "            print(cur_char + ': ' + row[3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d1ff7d-ca18-40e7-86ae-4af53bf31131",
   "metadata": {},
   "source": [
    "## chars without jyutping w/ pinyin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa9deec-4f6c-4926-877c-a36ce1506243",
   "metadata": {},
   "source": [
    "𫘤: ái\n",
    "𮩝: ài\n",
    "𩽾: ān\n",
    "鲃: bā\n",
    "𫜨: bà\n",
    "𫖔: bài\n",
    "𨭉: bān\n",
    "𠳐: bāng\n",
    "𬇙: bèi\n",
    "𮤲: bì\n",
    "𨚕: biàn\n",
    "𬭛: bō\n",
    "𬷕: bǔ\n",
    "𥮾: cǎn\n",
    "镵: chán\n",
    "𬊤: chǎn\n",
    "𬬮: chǎng\n",
    "𮧴: chàng\n",
    "𬘭: chēn\n",
    "铖: chéng\n",
    "𫄨: chī\n",
    "𫛶: chì\n",
    "䝙: chū\n",
    "𬸅: chú\n",
    "𬺓: chǔ\n",
    "𬭚: chún\n",
    "𫚖: cǐ\n",
    "酂: cuán\n",
    "酂: cuó又cuán\n",
    "𨱏: dā\n",
    "鿎: dá\n",
    "𫟼: dá\n",
    "𫄤: da\n",
    "𬘘: dǎn\n",
    "𫢸: dàn\n",
    "𣗋: dǎng\n",
    "𬍡: dàng\n",
    "𣱼: dāo\n",
    "䃅: dī\n",
    "𬱖: dí\n",
    "𤧛: dì\n",
    "䗖: dì\n",
    "𦰏: diào\n",
    "𫶇: dié\n",
    "𬟽: dōng\n",
    "𮙋: dú\n",
    "𬭊: dù\n",
    "𬭚: duì\n",
    "𫫇: è\n",
    "𫔍: fán\n",
    "𬸪: fán\n",
    "𬴂: fēi\n",
    "𣸣: fén\n",
    "𫓧: fū\n",
    "𫖯: fǔ\n",
    "𬮿: gài\n",
    "鿍: gàng\n",
    "鿔: gē\n",
    "𬮤: gé\n",
    "𮝴: gū\n",
    "䯄: guā\n",
    "𮉨: guā\n",
    "鳤: guǎn\n",
    "𨐈: guāng\n",
    "鬶: guī\n",
    "𭚦: guō\n",
    "啯: guō\n",
    "𬇹: guó\n",
    "𬌗: hé\n",
    "𮩝: hé\n",
    "𬭶: hēi\n",
    "𬣳: hén\n",
    "𫟹: hóng\n",
    "𭱊: hòng\n",
    "𬭤: hóu\n",
    "𬘫: huán\n",
    "𮝹: huán\n",
    "𤩽: huán\n",
    "𮝹: huàn\n",
    "𨱑: huáng\n",
    "㧑: huī\n",
    "𬭬: huì\n",
    "𬤝: huì\n",
    "𬴃: huō\n",
    "锪: huō\n",
    "𬯀: jī\n",
    "𫓹: jī\n",
    "𫌀: jī\n",
    "𬶨: jì\n",
    "𪟝: jì\n",
    "𬶭: jì\n",
    "𬂩: jiā\n",
    "篯: jiān\n",
    "𬣡: jiàn\n",
    "𬬱: jīn\n",
    "𬳶: jiōng\n",
    "䌹: jiǒng\n",
    "𬶋: jū\n",
    "钜: jù\n",
    "𪨗: juē\n",
    "𫘝: jué\n",
    "𫛞: jué\n",
    "𩾌: kāng\n",
    "𫸩: kōu\n",
    "𫛭: kuáng\n",
    "𫠆: kuǐ\n",
    "𬶟: là\n",
    "𬒗: lán\n",
    "𨱍: láng\n",
    "𫭼: láo\n",
    "𫄥: lí\n",
    "𫵷: lì\n",
    "𫟷: lì\n",
    "𬍛: lì\n",
    "梿: lián\n",
    "𬶠: liàn\n",
    "𫟅: liáng\n",
    "𬜯: liǎng\n",
    "𮉧: liǎng\n",
    "𪤗: liào\n",
    "𫚭: liè\n",
    "𬘭: lín\n",
    "𬴊: lín\n",
    "𬭸: lín\n",
    "𬕂: lǒng\n",
    "𪣻: lóu\n",
    "𦝼: lóu又lǘ\n",
    "硵: lǔ\n",
    "𫘧: lù\n",
    "𦝼: lǘ\n",
    "𬬭: lún\n",
    "𫭢: lún\n",
    "𫌨: luó\n",
    "㑩: luo\n",
    "祃: mà\n",
    "鿏: mài\n",
    "𬜬: màn\n",
    "𫞩: mén\n",
    "𫑡: méng\n",
    "𩾃: miǎn\n",
    "𬙊: mò\n",
    "𬭁: mǔ\n",
    "𫐐: ní\n",
    "𫠜: ní\n",
    "鿭: nǐ\n",
    "𨺙: nì\n",
    "𫔶: niè\n",
    "𬪩: nóng\n",
    "𫭟: ōu\n",
    "𬉼: ǒu\n",
    "𬳵: pī\n",
    "𬬫: pī\n",
    "𡎚: piǎn\n",
    "𬭯: piě\n",
    "𬞟: pín\n",
    "𨙸: qí\n",
    "𬨂: qí\n",
    ": qí\n",
    "伣: qiàn\n",
    "𬘬: qiàn\n",
    "𬧀: qiāng\n",
    "𬧀: qiàng\n",
    "𨱇: qiú\n",
    "𫭟: qū\n",
    "𪨰: qū\n",
    "𬒈: qué\n",
    "𫐓: róu\n",
    "𮉫: ruí\n",
    "𢫬: sà\n",
    "𫮃: shàn\n",
    "𪨶: shē\n",
    "𬳽: shēn\n",
    "𬬹: shén\n",
    "𫚕: shī\n",
    "𬤊: shì\n",
    "𬬸: shù\n",
    "𬢊: sì\n",
    "𫗧: sù\n",
    "𫟦: suì\n",
    "𬭼: suì\n",
    "鿎: tǎ\n",
    "𠉂: tà\n",
    "𬍡: tāng（又）\n",
    "𫘦: táo\n",
    "𫘨: tí\n",
    "𣨼: tì\n",
    "𫍣: tóng\n",
    "𬳿: tú\n",
    "𬯎: tuí\n",
    "𪨇: tuí\n",
    "𬶍: tuó\n",
    "𬇕: wàn\n",
    "𣲗: wéi\n",
    "𬶏: wéi\n",
    "𬀩: wěi\n",
    "𮧵: wěi\n",
    "𫇭: wěi\n",
    "𬱟: wěi\n",
    "鳚: wèi\n",
    "𬭬: wèi又huì\n",
    "𫘜: wén\n",
    "𬭩: wēng\n",
    "𣲘: wǔ\n",
    "㶉: xī\n",
    "锡: xī\n",
    "𫘬: xí\n",
    "𬭳: xǐ\n",
    "𬶮: xǐ\n",
    "𫰰: xiān\n",
    "𫍯: xián\n",
    "𤞤: xiǎn\n",
    "𬀪: xiàn\n",
    "𬭣: xiàn\n",
    "𬙋: xiāng\n",
    "蚃: xiǎng\n",
    "𫍲: xiǎo\n",
    "敩: xiào\n",
    "𫧯: xiè\n",
    "𬹼: xiè\n",
    "𤫉: xiè\n",
    "𫷷: xīn\n",
    "𫰛: xíng\n",
    "𬣙: xū\n",
    "媭: xū\n",
    "𦈡: xū\n",
    "𫓶: xuān\n",
    "𫍽: xuān\n",
    "𫠊: xuán\n",
    "碹: xuàn\n",
    "𫄸: xūn\n",
    "𬩽: xún\n",
    "㖊: xún\n",
    "𬍤: xún\n",
    "𬊈: xún\n",
    "𬘓: xún\n",
    "𫄧: yán\n",
    "𬸘: yǎn\n",
    "𬙂: yǎn\n",
    "𪩘: yǎn\n",
    "𫛩: yàn\n",
    "𬺈: yǐ\n",
    "𫖮: yǐ\n",
    "𬬩: yì\n",
    "𫄷: yì\n",
    "𬟁: yì\n",
    "𬘡: yīn\n",
    "𬤇: yīn\n",
    "𬮱: yīn\n",
    "訚: yín\n",
    "𦈠: yǐn\n",
    "𮐨: yīng\n",
    "𫘪: yuán\n",
    "𫐄: yuè\n",
    "𬸚: yuè\n",
    "𫖳: yūn\n",
    "筼: yún\n",
    "酂: zàn\n",
    "𥖨: zào\n",
    "𫗴: zhān\n",
    "𥇢: zhǎn\n",
    "𬬿: zhāo\n",
    "𬶐: zhào\n",
    "𦭜: zhī\n",
    "𬃊: zhì\n",
    "㤘: zhòu\n",
    "𬣞: zhǔ\n",
    "𬘯: zhǔn\n",
    "𬸦: zhuó\n",
    "咨: zī\n",
    "疭: zòng\n",
    "𮉪: zōu\n",
    "𨱔: zūn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10985ab-3745-467e-98af-d7676bdbfad5",
   "metadata": {},
   "source": [
    "### Pickle *dump* jp_mc_en file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6952dd2c-388c-4830-b9a9-99e9dbf64a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data (serialize)\n",
    "with open('jp_mc_en.pkl', 'wb') as handle:\n",
    "    pickle.dump(jp_and_mc_and_english, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f79e1c7-aca9-4ce5-aae8-e24b6123ba7b",
   "metadata": {},
   "source": [
    "### Pickle *load* jp_mc_en file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3ab42405-6f68-42a7-8355-1fc69757925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "jp_and_mc_and_english = pickle.load(open('jp_mc_en.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f392d38c-b0d5-4a1e-97a6-e50b4cadc0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jp': 'wu4', 'mc': '', 'en': 'old variant of 和[he2]'}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jp_and_mc_and_english['和3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9c3e9d32-0f15-49e7-a68e-241970898dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "Deck has been created.\n"
     ]
    }
   ],
   "source": [
    "import genanki\n",
    "import json\n",
    "import pycantonese\n",
    "import chinese_converter\n",
    "import csv\n",
    "\n",
    "# Create a new Anki deck with a unique ID and a name\n",
    "my_deck = genanki.Deck(\n",
    "  deck_id=123456790,\n",
    "  name=\"hanzi\",\n",
    ")\n",
    "\n",
    "answer_side = \"\"\"{{FrontSide}}<hr id='answer'>\n",
    "    {{Pinyin}}<br>\n",
    "    {{Jyutping}}<br><br>\n",
    "    {{MiddleChinese}}<br><br>\n",
    "    {{Definition}}<br><br>\n",
    "    {{English}}<br><br>\n",
    "    {{Stroke}} {{Level}} {{Page}}\n",
    "    \"\"\"\n",
    "# Define a model (template) for the cards\n",
    "# A model specifies the fields and card format\n",
    "my_model = genanki.Model(\n",
    "  model_id=123456790,\n",
    "  name=\"Basic Model\",\n",
    "  fields=[\n",
    "    {\"name\": \"Character\"},\n",
    "    {\"name\": \"Pinyin\"},\n",
    "    {\"name\": \"Jyutping\"},\n",
    "    {\"name\": \"MiddleChinese\"},\n",
    "    {\"name\": \"Definition\"},\n",
    "    {\"name\": \"English\"},\n",
    "    {\"name\": \"Stroke\"},\n",
    "    {\"name\": \"Level\"},\n",
    "    {\"name\": \"Page\"},\n",
    "    #{\"name\": \"image\"},\n",
    "  ],templates=[\n",
    "    {\n",
    "      \"name\": \"Card 1\",\n",
    "      \"qfmt\": \"<span class='char'>{{Character}}</span>\", # Question format\n",
    "      \"afmt\": answer_side, # Answer format\n",
    "      #\"afmt\": \"{{FrontSide}}<hr id='answer'>{{Answer}}<br>{{image}}\", # Answer format\n",
    "    },\n",
    "  ],\n",
    "  css=\"\"\"\n",
    "  .card {\n",
    "   font-family: arial;\n",
    "   font-size: 20px;\n",
    "   text-align: center;\n",
    "   color: black;\n",
    "   background-color: white;\n",
    "  }\n",
    "\n",
    "  .char {\n",
    "    font-size: 200%;\n",
    "  }\n",
    "  \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "with open('xhzd_corrected.csv', newline='', encoding='utf-8') as csvfile:\n",
    "\n",
    "    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    chars = set()\n",
    "    \n",
    "    for row in spamreader:\n",
    "\n",
    "        cur_char = ''\n",
    "        \n",
    "        if row[0][0] == ' ':\n",
    "            cur_char = row[0][1]\n",
    "        else:\n",
    "            cur_char = row[0][0]\n",
    "\n",
    "        j = 0;\n",
    "\n",
    "        if cur_char not in chars:\n",
    "            chars.add(cur_char)\n",
    "        else:\n",
    "            j = 2\n",
    "            while cur_char + str(j) in chars:\n",
    "                j += 1\n",
    "            cur_char = cur_char + str(j)\n",
    "            chars.add(cur_char)\n",
    "\n",
    "        if j == 0:\n",
    "            j = ''\n",
    "\n",
    "        \n",
    "        prons = jp_and_mc_and_english[cur_char]\n",
    "\n",
    "        jyutping = prons['jp']\n",
    "        mc = prons['mc']\n",
    "        english = prons['en']\n",
    "        \n",
    "        # Add a card to the deck\n",
    "        note = genanki.Note(\n",
    "            model=my_model,\n",
    "            fields=[row[0] + str(j), row[3], jyutping, mc, row[6], english, row[5], row[4], row[1] + \"页\"] #fields=[\"What is the capital of France?\", \"Paris\",'<img src=\"image.gif\">'],) # add note to deck my_deck.add_note(note)\n",
    "        )\n",
    "        \n",
    "        my_deck.add_note(note)\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "    \n",
    "        i += 1\n",
    "    \n",
    "\n",
    "\n",
    "# create package for deck\n",
    "my_package = genanki.Package(my_deck)\n",
    "\n",
    "# Optionally, add more cards here in a similar manner\n",
    "#my_package.media_files = ['image.gif']\n",
    "\n",
    "# Save the deck to a file\n",
    "my_package.write_to_file('hanzi.apkg')\n",
    "\n",
    "print(\"Deck has been created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b1ab80-7b3d-4be3-8d41-332e9d795d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import genanki\n",
    "import json\n",
    "import pycantonese\n",
    "\n",
    "# Create a new Anki deck with a unique ID and a name\n",
    "my_deck = genanki.Deck(\n",
    "  deck_id=123456789,\n",
    "  name=\"idoms\",\n",
    ")\n",
    "\n",
    "# Define a model (template) for the cards\n",
    "# A model specifies the fields and card format\n",
    "my_model = genanki.Model(\n",
    "  model_id=123456789,\n",
    "  name=\"Basic Model\",\n",
    "  fields=[\n",
    "    {\"name\": \"Question\"},\n",
    "    {\"name\": \"Answer\"},\n",
    "    #{\"name\": \"image\"},\n",
    "  ],\n",
    "  templates=[\n",
    "    {\n",
    "      \"name\": \"Card 1\",\n",
    "      \"qfmt\": \"{{Question}}\", # Question format\n",
    "      \"afmt\": \"{{FrontSide}}<hr id='answer'>{{Answer}}\", # Answer format\n",
    "      #\"afmt\": \"{{FrontSide}}<hr id='answer'>{{Answer}}<br>{{image}}\", # Answer format\n",
    "    },\n",
    "  ],\n",
    "  css=\"\"\"\n",
    "  .card {\n",
    "   font-family: arial;\n",
    "   font-size: 20px;\n",
    "   text-align: center;\n",
    "   color: black;\n",
    "   background-color: white;\n",
    "  }\n",
    "  \"\"\",\n",
    ")\n",
    "\n",
    "f = open('idiom.json',)\n",
    "data = json.load(f)\n",
    "\n",
    "for entry in data:\n",
    "    # Add a card to the deck\n",
    "    note = genanki.Note(\n",
    "      model=my_model,\n",
    "      fields=[entry['explanation'] + '<br><br>' + entry['example'], \n",
    "              chinese_converter.to_traditional(entry['word']) + '<br>' + entry['word'] + \n",
    "              '<br>' + entry['pinyin'] + '<br>' + pycantonese.characters_to_jyutping(entry['word'])[0][1] +\n",
    "              '<br><br>' + entry['derivation']],\n",
    "      #fields=[\"What is the capital of France?\", \"Paris\",'<img src=\"image.gif\">'],\n",
    "    )\n",
    "\n",
    "    # add note to deck\n",
    "    my_deck.add_note(note)\n",
    "\n",
    "# create package for deck\n",
    "my_package = genanki.Package(my_deck)\n",
    "\n",
    "# Optionally, add more cards here in a similar manner\n",
    "#my_package.media_files = ['image.gif']\n",
    "\n",
    "# Save the deck to a file\n",
    "my_package.write_to_file('idoms.apkg')\n",
    "\n",
    "print(\"Deck has been created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "96f66036-925a-4f87-868c-ef893a149b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse line: 【六一儿童节】Liù－YīÉrtónɡJié全世界儿童的节日。国际民主妇女联合会为保障全世界儿童的权利，于1949年在莫斯科举行的会议上，决定以6月1日为国际儿童节。也叫六一国际儿童节、国际儿童节、儿童节。 with error local variable 'types' referenced before assignment\n",
      "Failed to parse line: 【碌】liù with error local variable 'types' referenced before assignment\n",
      "[{'word': '六艺',\n",
      "  'pinyin': 'liùyì',\n",
      "  'types': ['名'],\n",
      "  'definitions': ['古代指礼（礼仪）、乐（音乐）、射（射箭）、御（驾车）、书（识字）、数（计算）等六种科目。',\n",
      "                  '古代指《诗》、《书》、《礼》、《乐》、《易》、《春秋》六种儒家经书。']},\n",
      " {'word': '六欲',\n",
      "  'pinyin': 'liùyù',\n",
      "  'types': ['名'],\n",
      "  'definitions': ['佛教指色欲、形貌欲等六种欲望，泛指人的各种欲望：七情～。']},\n",
      " {'word': '六指儿',\n",
      "  'pinyin': 'liùzhǐr',\n",
      "  'types': ['名'],\n",
      "  'definitions': ['长了六个指头的手或脚。', '指手或脚上长有六个指头的人。']},\n",
      " {'word': '陆',\n",
      "  'pinyin': '（陸）liù',\n",
      "  'types': ['数'],\n",
      "  'definitions': ['“六”的大写。参看1271页【数字】。另见887页lù。']}]\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Sample dictionary data\n",
    "dictionary_text = \"\"\"\n",
    "【六一儿童节】Liù－YīÉrtónɡJié全世界儿童的节日。国际民主妇女联合会为保障全世界儿童的权利，于1949年在莫斯科举行的会议上，决定以6月1日为国际儿童节。也叫六一国际儿童节、国际儿童节、儿童节。\n",
    "【六艺】liùyì〈名〉❶古代指礼（礼仪）、乐（音乐）、射（射箭）、御（驾车）、书（识字）、数（计算）等六种科目。❷古代指《诗》、《书》、《礼》、《乐》、《易》、《春秋》六种儒家经书。\n",
    "【六欲】liùyù〈名〉佛教指色欲、形貌欲等六种欲望，泛指人的各种欲望：七情～。\n",
    "【六指儿】liùzhǐr〈名〉❶长了六个指头的手或脚。❷指手或脚上长有六个指头的人。\n",
    "【陆】（陸）liù〈数〉“六”的大写。参看1271页【数字】。另见887页lù。\n",
    "【碌】liù\n",
    "\"\"\"\n",
    "\n",
    "# Regex to parse an entry line\n",
    "entry_pattern = re.compile(r'【(.*?)】(.*?)((?:〈.*?〉)+)(.*)')\n",
    "\n",
    "def parse_entry(line):\n",
    "    match = entry_pattern.match(line)\n",
    "    if match:\n",
    "        word = match.group(1)\n",
    "        pinyin = match.group(2).strip().lower()\n",
    "        types_defs = match.group(3)\n",
    "        definitions_text = match.group(4)\n",
    "\n",
    "        # Extract types\n",
    "        types = re.findall(r'〈(.*?)〉', types_defs)\n",
    "\n",
    "        # Handle cases where definitions might not be properly captured\n",
    "        if not definitions_text:\n",
    "            definitions_text = \"\"\n",
    "\n",
    "        # Split definitions if they are numbered\n",
    "        if any(num in definitions_text for num in '❶❷❸❹❺❻❼❽❾❿⓫⓬⓭⓮⓯⓰⓱⓲⓳⓴'):\n",
    "            definitions = re.split(r'❶|❷|❸|❹|❺|❻|❼|❽|❾|❿|⓫|⓬|⓭|⓮|⓯|⓰|⓱|⓲|⓳|⓴', definitions_text)\n",
    "        else:\n",
    "            definitions = [definitions_text]\n",
    "\n",
    "        # Clean definitions\n",
    "        definitions = [defn.strip() for defn in definitions if defn.strip()]\n",
    "\n",
    "        return {\n",
    "            \"word\": word,\n",
    "            \"pinyin\": pinyin,\n",
    "            \"types\": types,\n",
    "            \"definitions\": definitions\n",
    "        }\n",
    "    else:\n",
    "        word = re.search(r'【(.*?)】',line)[1]\n",
    "\n",
    "        if len(word) + 2 != len(line):\n",
    "            pinyin = re.search(r'[a-zāáǎàōóǒòēéěèīíǐìūúǔùüǖǘǚǜêê̄ếê̌ềm̄ḿm̀ńňǹẑĉŝŋɡ]+',line)[0]\n",
    "            definition = re.search(r'[a-zāáǎàōóǒòēéěèīíǐìūúǔùüǖǘǚǜêê̄ếê̌ềm̄ḿm̀ńňǹẑĉŝŋɡ]+(\\s*(.*))',line)[1]\n",
    "        else:\n",
    "            pinyin = ''\n",
    "            definition = ''\n",
    "        \n",
    "        if len(word) == 4:\n",
    "            types = ['四']\n",
    "        else:\n",
    "            []\n",
    "        \n",
    "        return {\"word\": word, \"pinyin\": pinyin, \"types\": types, \"definitions\": definition}\n",
    "\n",
    "# Parsing the dictionary\n",
    "entries = []\n",
    "for line in dictionary_text.strip().split('\\n'):\n",
    "    try:\n",
    "        entry = parse_entry(line)\n",
    "        if entry['word']:  # Only append if word is not empty\n",
    "            entries.append(entry)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to parse line: {line} with error {str(e)}\")\n",
    "\n",
    "# Print the parsed dictionary entries\n",
    "from pprint import pprint\n",
    "pprint(entries, sort_dicts=False)\n",
    "print(len(entries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c6719a-500d-4ce9-8f7f-0e08fb9e99c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
